import os
import chromadb
from dotenv import load_dotenv
from typing import Optional, Dict, Any, List
from langchain_openai import OpenAIEmbeddings 

load_dotenv()

# --- ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šè‡ªå®šä¹‰é€‚é…å™¨ç±» ---
# è¿™æ˜¯ä¸€ä¸ªâ€œèƒ¶æ°´â€ç±»ï¼Œè´Ÿè´£æŠŠ ChromaDB çš„è¯·æ±‚è½¬å‘ç»™ OpenRouter
class OpenRouterEmbeddingFunction:
    def __init__(self):
        # åˆå§‹åŒ– LangChain çš„ Embedding å·¥å…·
        api_key = os.environ.get("OPENAI_API_KEY")
        api_base = os.environ.get("OPENAI_BASE_URL", "https://openrouter.ai/api/v1")
        
        if not api_key:
            # é˜²æ­¢æ²¡æœ‰ key æ—¶æŠ¥é”™ï¼Œç»™ä¸€ä¸ªå‡ key å ä½ï¼ˆè¿è¡Œæ—¶ä¼šæŠ›é”™ï¼Œä½†å¯åŠ¨ä¸å´©ï¼‰
            print("âš ï¸ Warning: OPENAI_API_KEY not found in environment.")
            api_key = "sk-placeholder"

        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small", # OpenRouter æ”¯æŒçš„é«˜æ€§ä»·æ¯”æ¨¡å‹
            openai_api_key=api_key,
            openai_api_base=api_base,
            check_embedding_ctx_length=False
        )

    # ChromaDB è¦æ±‚çš„æ ‡å‡†æ¥å£ï¼šæ¥æ”¶æ–‡æœ¬åˆ—è¡¨ï¼Œè¿”å›å‘é‡åˆ—è¡¨
    def __call__(self, input: List[str]) -> List[List[float]]:
        # è°ƒç”¨ API ç”Ÿæˆå‘é‡
        return self.embeddings.embed_documents(input)

# --- é…ç½® Embedding ---
EMBEDDING_FUNC = OpenRouterEmbeddingFunction()

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = chromadb.PersistentClient(path="./chroma_db")
collection = client.get_or_create_collection(
    name="knowledge_base",
    embedding_function=EMBEDDING_FUNC
)

def add_memory(
    page_id: str,
    text: str, 
    *,
    title: str = None,
    domain: str = None, 
    metadata: Optional[Dict[str, Any]] = None,
):
    """
    å°†é¡µé¢å†…å®¹å­˜å…¥å‘é‡æ•°æ®åº“è®°å¿†åº“
    """
    # 1. å‚æ•°å½’ä¸€åŒ–
    final_metadata = dict(metadata) if metadata else {}
    
    # æå–æ ‡é¢˜
    final_title = title or final_metadata.get("title") or "Untitled"
    
    # æå–åˆ†ç±»/é¢†åŸŸ
    final_domain = domain or final_metadata.get("domain") or "General"
    
    # 2. å®‰å…¨æ£€æŸ¥
    if not text or not isinstance(text, str) or len(text.strip()) < 10:
        print("âŒ VectorOps: content too short or missing, skip memory.")
        return False

    # 3. å‡†å¤‡ Metadata 
    final_metadata.setdefault("title", final_title)
    final_metadata.setdefault("domain", final_domain) 
    final_metadata.setdefault("category", final_domain) 
    
    # æˆªå–æ­£æ–‡å­˜å…¥ metadata
    final_metadata["content"] = text[:3000] 
    final_metadata.setdefault("url", "")

    # æ¸…æ´— None 
    cleaned_metadata = {k: str(v) for k, v in final_metadata.items() if v is not None}

    print(f"ğŸ’¾ Vectorizing memory: {final_title}...")

    # 4. æ„å»º Embedding æ–‡æœ¬
    summary_text = final_metadata.get("summary", "")
    dense_content = text[:3000].replace("\n", " ")
    
    embedding_text = (
        f"Title: {final_title}\n"
        f"Keywords: {final_title} {final_domain}\n"
        f"Summary: {summary_text}\n"
        f"Snippet: {dense_content}"
    )

    # 5. å†™å…¥å‘é‡æ•°æ®åº“
    try:
        collection.add(
            documents=[embedding_text],
            metadatas=[cleaned_metadata],
            ids=[page_id],
        )
        print("âœ… Memory stored in Vector DB.")
        return True
    except Exception as e:
        print(f"âŒ Failed to store vector: {e}")
        return False

def search_memory(
    query_text: str,
    n_results: int = 5,
    domain: str = None 
) -> Dict[str, Any]:
    """
    ä»å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢ç›¸å…³è®°å¿†
    """
    if not isinstance(query_text, str) or len(query_text.strip()) < 2:
        return {"match": False}

    filter_msg = domain if domain and domain != "All" else "None"
    print(f"ğŸ” Vector Searching for: {query_text[:20]}... (Filter: {filter_msg})")
    
    query_args = {
        "query_texts": [query_text],
        "n_results": n_results 
    }
    
    if domain and domain not in ["All", None]:
        query_args["where"] = {"domain": domain}

    try:
        results = collection.query(**query_args)
        
        if not results['ids'] or len(results['ids'][0]) == 0:
            print("   No results found.")
            return {"match": False}

        # éå† Top-K ç»“æœ
        count = len(results['ids'][0])
        print(f"   -------- Top {count} Candidates --------")
        
        # ğŸ”¥ ä¿®æ”¹ç‚¹4ï¼šOpenAI Embedding çš„ä½™å¼¦è·ç¦»é€šå¸¸è¾ƒå°
        THRESHOLD = 0.7  
        
        for i in range(count):
            dist = results['distances'][0][i]
            meta = results['metadatas'][0][i]
            title = meta.get("title", "Untitled")
            
            print(f"   #{i+1}: {title} (Dist: {dist:.4f})")
            
            if dist < THRESHOLD:
                best_candidate = {
                    "match": True,
                    "page_id": results['ids'][0][i],
                    "title": title,
                    "distance": dist,
                    "metadata": meta,
                }
                print(f"   âœ… Selected: {title}")
                return best_candidate
        
        print("âŒ No candidate met the threshold.")
        return {"match": False}

    except Exception as e:
        print(f"âŒ Vector Search Error: {e}")
        return {"match": False}